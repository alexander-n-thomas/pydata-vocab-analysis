{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocabulary Analysis Workshop\n",
    "\n",
    "## $\\mbox{TF.IDF}$\n",
    "\n",
    "The motivation for $\\mbox{TF.IDF}$ is wanting to look at words that make documents stand out. These words are considered important for the document. If a word occurs in most documents, that may not be interesting to us. Similarly, if a word only occurs once in one document that is also not useful in summarizing our text. We want to see the words that occur often in a limited number of documents. This is why we are interested in the number of times a word occurs, and the number of documents it occurs in.\n",
    "\n",
    "$\\mbox{TF}$ stands for term frequency  \n",
    "$\\mbox{IDF}$ stands for inverse document frequency\n",
    "\n",
    "There are many flavors of $\\mbox{TF.IDF}$, let's look at one of the more common formulations.\n",
    "\n",
    "Although $\\mbox{TF}$ stands for term frequency, raw counts are often used instead. Similarly, $\\mbox{IDF}$ is often the $log$ of the inverse document frequency.\n",
    "\n",
    "Here is the mathematical definition for the flavor of $\\mbox{TF.IDF}$ we will be using.\n",
    "\n",
    "$$\n",
    "\\begin{array}{l}\n",
    "D\\ :=\\ \\text{a collection of documents}\\\\\n",
    "d\\ :=\\ \\text{a document in $D$}\\\\\n",
    "t\\ :=\\ \\text{a term}\\\\\n",
    "N\\ :=\\ |D|\\\\\n",
    "n_{t}\\ :=\\ |\\{d\\ :\\ t \\in d\\}|\\\\\n",
    "\\mbox{TF}(t, d)\\ :=\\ \\text{number of times $t$ occurs in $d$}\\\\\n",
    "\\mbox{IDF}(t)\\ :=\\ \\log_2{(1+\\frac{N}{n_{t}})}\\\\\n",
    "\\mbox{TF.IDF}(t, d)\\ :=\\ \\mbox{TF}(t, d)\\times\\mbox{IDF}(t)\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "We will be looking at the average $\\mbox{TF.IDF}$ for words\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\overline{\\mbox{TF.IDF}(t, d)}\\ &=\\ \\frac{\\sum_{d \\in D}{\\mbox{TF.IDF}(t, d)}}{N}\\\\\n",
    "&=\\ \\frac{\\sum_{d \\in D}{\\mbox{TF}(t, d)\\times\\mbox{IDF}(t)}}{N}\\\\\n",
    "&=\\ \\mbox{IDF}(t)\\times\\frac{\\sum_{d \\in D}{\\mbox{TF}(t, d)}}{N}\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "As one might imagine, this is still susceptible to words that have a high-enough $\\mbox{TF}$ to diminish the effect of $\\mbox{IDF}$.\n",
    "\n",
    "(tf-idf [wikipedia](https://en.wikipedia.org/wiki/Tf%E2%80%93idf))\n",
    "\n",
    "We will produce two kinds of visualizations using $\\mbox{TF.IDF}$.\n",
    "\n",
    "1. A plot of $\\mbox{TF}$ vs $\\mbox{IDF}$\n",
    "2. A word cloud, which is where we display our vocabulary with size proportional to some weight ($\\mbox{TF.IDF}$)\n",
    "\n",
    "You will sometimes here this kind of approach called to as the _bag-of-words_ approach. This is referring to how the documents are treated like _bags_. A _bag_ (AKA [_multiset_](https://en.wikipedia.org/wiki/Multiset)), in this context, is a collection of things with counts of occurrences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from vocab_analysis import *\n",
    "\n",
    "import answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jobs_df = pd.read_pickle('./data/tokenized.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>experience</th>\n",
       "      <th>education</th>\n",
       "      <th>is_hourly</th>\n",
       "      <th>is_part_time</th>\n",
       "      <th>is_supervisor</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>THE COMPANY    Employer is a midstream service...</td>\n",
       "      <td>5+</td>\n",
       "      <td>none</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[THE, COMPANY, Employer, is, a, midstream, ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ICR Staffing is now accepting resumes for Indu...</td>\n",
       "      <td>2-5</td>\n",
       "      <td>none</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[ICR, Staffing, is, now, accepting, resumes, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a great position for the right person....</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[This, is, a, great, position, for, the, right...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A large multi-specialty health center is expan...</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[A, large, multi, -, specialty, health, center...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JOB PURPOSE:    The Account Director is respon...</td>\n",
       "      <td>5+</td>\n",
       "      <td>bs-degree-needed</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[JOB, PURPOSE, :, The, Account, Director, is, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          description experience  \\\n",
       "id                                                                 \n",
       "0   THE COMPANY    Employer is a midstream service...         5+   \n",
       "1   ICR Staffing is now accepting resumes for Indu...        2-5   \n",
       "2   This is a great position for the right person....       none   \n",
       "3   A large multi-specialty health center is expan...       none   \n",
       "4   JOB PURPOSE:    The Account Director is respon...         5+   \n",
       "\n",
       "           education  is_hourly  is_part_time  is_supervisor  \\\n",
       "id                                                             \n",
       "0               none      False         False           True   \n",
       "1               none      False         False          False   \n",
       "2               none      False          True          False   \n",
       "3               none      False         False          False   \n",
       "4   bs-degree-needed      False         False           True   \n",
       "\n",
       "                                               tokens  \n",
       "id                                                     \n",
       "0   [THE, COMPANY, Employer, is, a, midstream, ser...  \n",
       "1   [ICR, Staffing, is, now, accepting, resumes, f...  \n",
       "2   [This, is, a, great, position, for, the, right...  \n",
       "3   [A, large, multi, -, specialty, health, center...  \n",
       "4   [JOB, PURPOSE, :, The, Account, Director, is, ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_avg_tfidf(term_rows):\n",
    "    bags = term_rows.apply(Counter) # convert the documents to bags, this will calculate the TF per document per term\n",
    "    sum_tf = Counter() # this will hold the sum of the TF per term\n",
    "    df = Counter() # this will calculate the raw DF (n_t from above)\n",
    "    for bag in bags:\n",
    "        sum_tf.update(bag)\n",
    "        df.update(bag.keys())\n",
    "    sum_tf = pd.Series(sum_tf)\n",
    "    df = pd.Series(df)\n",
    "    idf = np.log2(1 + len(term_rows) / df)\n",
    "    sum_tfidf = sum_tf * idf # this will calculate the sum TF.IDF per term\n",
    "    avg_tfidf = sum_tfidf / len(term_rows)  # this will calculate the average TF.IDF per term over the documents\n",
    "    return pd.DataFrame({'sum_tf': sum_tf, 'idf': idf, 'avg_tfidf': avg_tfidf})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_tfidf_df = calculate_avg_tfidf(jobs_df['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_tfidf</th>\n",
       "      <th>idf</th>\n",
       "      <th>sum_tf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35005.000000</td>\n",
       "      <td>35005.000000</td>\n",
       "      <td>35005.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.031410</td>\n",
       "      <td>10.455301</td>\n",
       "      <td>38.978117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.192839</td>\n",
       "      <td>2.131884</td>\n",
       "      <td>697.780197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.002765</td>\n",
       "      <td>1.008819</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.002765</td>\n",
       "      <td>9.512082</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.005072</td>\n",
       "      <td>11.095727</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.016636</td>\n",
       "      <td>12.095397</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.572458</td>\n",
       "      <td>12.095397</td>\n",
       "      <td>61839.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          avg_tfidf           idf        sum_tf\n",
       "count  35005.000000  35005.000000  35005.000000\n",
       "mean       0.031410     10.455301     38.978117\n",
       "std        0.192839      2.131884    697.780197\n",
       "min        0.002765      1.008819      1.000000\n",
       "25%        0.002765      9.512082      1.000000\n",
       "50%        0.005072     11.095727      2.000000\n",
       "75%        0.016636     12.095397      8.000000\n",
       "max       14.572458     12.095397  61839.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_tfidf_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's look at the distribution of $\\sum_{d \\in D}{\\mbox{TF}(t, d)}$ vs $\\mbox{IDF}(t)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_tfidf</th>\n",
       "      <th>idf</th>\n",
       "      <th>sum_tf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Terrell</th>\n",
       "      <td>0.002765</td>\n",
       "      <td>12.095397</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SDO</th>\n",
       "      <td>0.002765</td>\n",
       "      <td>12.095397</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SDLO</th>\n",
       "      <td>0.002765</td>\n",
       "      <td>12.095397</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SDH</th>\n",
       "      <td>0.002765</td>\n",
       "      <td>12.095397</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SDC</th>\n",
       "      <td>0.002765</td>\n",
       "      <td>12.095397</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         avg_tfidf        idf  sum_tf\n",
       "Terrell   0.002765  12.095397       1\n",
       "SDO       0.002765  12.095397       1\n",
       "SDLO      0.002765  12.095397       1\n",
       "SDH       0.002765  12.095397       1\n",
       "SDC       0.002765  12.095397       1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_tfidf_df.sort_values('sum_tf').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_tfidf</th>\n",
       "      <th>idf</th>\n",
       "      <th>sum_tf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>14.572458</td>\n",
       "      <td>1.030976</td>\n",
       "      <td>61839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>14.432160</td>\n",
       "      <td>1.021578</td>\n",
       "      <td>61807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>13.614096</td>\n",
       "      <td>1.008819</td>\n",
       "      <td>59041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>7.681988</td>\n",
       "      <td>1.045957</td>\n",
       "      <td>32132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>6.428974</td>\n",
       "      <td>1.110939</td>\n",
       "      <td>25318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     avg_tfidf       idf  sum_tf\n",
       ",    14.572458  1.030976   61839\n",
       "and  14.432160  1.021578   61807\n",
       ".    13.614096  1.008819   59041\n",
       "to    7.681988  1.045957   32132\n",
       "the   6.428974  1.110939   25318"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_tfidf_df.sort_values('sum_tf', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_tfidf</th>\n",
       "      <th>idf</th>\n",
       "      <th>sum_tf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>13.614096</td>\n",
       "      <td>1.008819</td>\n",
       "      <td>59041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>14.432160</td>\n",
       "      <td>1.021578</td>\n",
       "      <td>61807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>14.572458</td>\n",
       "      <td>1.030976</td>\n",
       "      <td>61839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>7.681988</td>\n",
       "      <td>1.045957</td>\n",
       "      <td>32132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>4.933866</td>\n",
       "      <td>1.060095</td>\n",
       "      <td>20362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     avg_tfidf       idf  sum_tf\n",
       ".    13.614096  1.008819   59041\n",
       "and  14.432160  1.021578   61807\n",
       ",    14.572458  1.030976   61839\n",
       "to    7.681988  1.045957   32132\n",
       "a     4.933866  1.060095   20362"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_tfidf_df.sort_values('idf').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_tfidf</th>\n",
       "      <th>idf</th>\n",
       "      <th>sum_tf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Terrell</th>\n",
       "      <td>0.002765</td>\n",
       "      <td>12.095397</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MindBody</th>\n",
       "      <td>0.002765</td>\n",
       "      <td>12.095397</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Milestone</th>\n",
       "      <td>0.002765</td>\n",
       "      <td>12.095397</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employement</th>\n",
       "      <td>0.002765</td>\n",
       "      <td>12.095397</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emploment</th>\n",
       "      <td>0.002765</td>\n",
       "      <td>12.095397</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             avg_tfidf        idf  sum_tf\n",
       "Terrell       0.002765  12.095397       1\n",
       "MindBody      0.002765  12.095397       1\n",
       "Milestone     0.002765  12.095397       1\n",
       "employement   0.002765  12.095397       1\n",
       "emploment     0.002765  12.095397       1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_tfidf_df.sort_values('idf', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_tfidf</th>\n",
       "      <th>idf</th>\n",
       "      <th>sum_tf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Terrell</th>\n",
       "      <td>0.002765</td>\n",
       "      <td>12.095397</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SWMPs</th>\n",
       "      <td>0.002765</td>\n",
       "      <td>12.095397</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SWM</th>\n",
       "      <td>0.002765</td>\n",
       "      <td>12.095397</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SWIFT</th>\n",
       "      <td>0.002765</td>\n",
       "      <td>12.095397</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SWCC</th>\n",
       "      <td>0.002765</td>\n",
       "      <td>12.095397</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         avg_tfidf        idf  sum_tf\n",
       "Terrell   0.002765  12.095397       1\n",
       "SWMPs     0.002765  12.095397       1\n",
       "SWM       0.002765  12.095397       1\n",
       "SWIFT     0.002765  12.095397       1\n",
       "SWCC      0.002765  12.095397       1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_tfidf_df.sort_values('avg_tfidf').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_tfidf</th>\n",
       "      <th>idf</th>\n",
       "      <th>sum_tf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>14.572458</td>\n",
       "      <td>1.030976</td>\n",
       "      <td>61839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>14.432160</td>\n",
       "      <td>1.021578</td>\n",
       "      <td>61807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>13.614096</td>\n",
       "      <td>1.008819</td>\n",
       "      <td>59041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>•</th>\n",
       "      <td>9.810510</td>\n",
       "      <td>2.088409</td>\n",
       "      <td>20552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>*</th>\n",
       "      <td>7.972788</td>\n",
       "      <td>2.121841</td>\n",
       "      <td>16439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     avg_tfidf       idf  sum_tf\n",
       ",    14.572458  1.030976   61839\n",
       "and  14.432160  1.021578   61807\n",
       ".    13.614096  1.008819   59041\n",
       "•     9.810510  2.088409   20552\n",
       "*     7.972788  2.121841   16439"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_tfidf_df.sort_values('avg_tfidf', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When searching a document, the final score is often calculated as the sum of the $\\mbox{TF.IDF}$ for each term in the query.\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{array}{l}\n",
    "D\\ :=\\ \\text{a collection of documents}\\\\\n",
    "d\\ :=\\ \\text{a document in $D$}\\\\\n",
    "q\\ :=\\ \\text{a set of terms}\n",
    "t\\ :=\\ \\text{a term}\\\\\n",
    "\\mbox{TF.IDF}(t, d)\\ :=\\ \\mbox{TF}(t, d)\\times\\mbox{IDF}(t)\\\\\n",
    "score(q, d)\\ :=\\ \\sum_{t \\in q}{\\mbox{TF.IDF}(t, d)}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Let's build a function for searching our corpus.\n",
    "First, let's build our _index_ from documents to $TF$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "0    {u'limited': 2, u'distributors': 2, u'-': 4, u...\n",
       "1    {u'shop': 1, u'United': 1, u'background': 1, u...\n",
       "2    {u'HEALTHCAREseeker': 1, u'being': 1, u'bring'...\n",
       "3    {u'and': 3, u'dedicated': 1, u'be': 1, u'expan...\n",
       "4    {u'limited': 3, u'all': 12, u'KNOWLEDGE': 2, u...\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_index = jobs_df['tokens'].apply(Counter)\n",
    "doc_index.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to build an _inverted index_ from terms to documents. This will let us quickly filter to a subset of documents for calculating $TF.IDF$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "!     {3887, 2, 2051, 2052, 10, 4107, 2050, 4110, 15...\n",
       "\"     {3073, 2731, 5, 4102, 1032, 3887, 1548, 3597, ...\n",
       "#     {3588, 2055, 4268, 4110, 2576, 17, 18, 1043, 2...\n",
       "$     {2191, 1818, 1691, 1819, 4265, 4271, 823, 1211...\n",
       "$.                                               {1512}\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_index = defaultdict(set)\n",
    "for ix, bag in doc_index.iteritems():\n",
    "    for term in bag:\n",
    "        inv_index[term].add(ix)\n",
    "inv_index = pd.Series(inv_index)\n",
    "inv_index.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from my_tokenize import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search(query, docs, doc_index, inv_index, idf, processing, limit=10):\n",
    "    terms = set(processing(query)) # always process your queries like you process your documents\n",
    "    filter_set_ixs = set()\n",
    "    term_idfs = idf[terms]\n",
    "    for term in terms:\n",
    "        filter_set_ixs |= inv_index.loc[term]\n",
    "    # we should only return documents that contain at least one word from the query\n",
    "    filter_set = doc_index.loc[filter_set_ixs]\n",
    "    tf_df = pd.DataFrame({term: filter_set.apply(lambda bag: bag[term]) for term in terms})\n",
    "    tfidf_df = tf_df * term_idfs\n",
    "    score_df = tfidf_df.apply(np.sum, axis=1).sort_values(ascending=False)\n",
    "    for doc_id, score in score_df[:limit].iteritems():\n",
    "        print('=' * 80)\n",
    "        print(doc_id)\n",
    "        print('=' * 30)\n",
    "        print(docs.loc[doc_id])\n",
    "        print('=' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "3489\n",
      "==============================\n",
      "We have a  DB2 DBA fulltime opportunity in Houston, TX,  Job desc is as follows. ---------------- Interview type : Telephone, followed by Skype / in-person.  You will be  responsible for administration of the database management subsystems that reside on the mainframe and midrange platforms.These data base management systems include IMS and all variations of DB2.  ·Assist in the analysis and design of logical and physical data base structures including conceptual design, data modeling, and physical implementation  ·Consult with Application Development and Computing Division personnel on data base application performance, tuning, and debugging  ·Assist with the design and implementation of procedures to ensure recoverability of corporate data resources  ·Assist with the installation, maintenance, and administration of data base related software utilities and tools  ·Maintain multi-tier data base environments including object migrations between those tiers  ·Perform data base maintenance/tuning and monitor performance to ensure that response meets or exceeds expectations  ·Create and maintain documentation as it relates to the data base environment  ·Participates in Rotating on-call after hours support  ·Must be self-motivated, team-oriented and ableto operate with minimal supervision  ·Strong analytical and problem solving skills  ·Ability to multitask effectively in a fast paced environment  ·Good written, oral, and interpersonal communication skills  ·Ability to conduct research and teach yourself  ·Creativity in proactively developing approaches to problems, recommending actions and implementing those recommendations.  ·A minimum of 3 years of experience in application programming, with two of those being directly related to the development of data base application  ·Working understanding of data analysis,modeling, and data base design methods and techniques.  ·Competent in basic data base administration tasks including the definition/alteration of data base objects, utility processing, security, backup/recovery, and performance and tuning.  ·Experience with DB2 for z/OS  ·Proficient in both written and oral communications skills.  ----------------  Do reply with  updated resume specific to this requirement, residency status, contact #, start date and expected salary per annum.  Look forward to hear from you, have a great day.  regards,  Vishe Muni. Goodtracks.\n",
      "================================================================================\n",
      "================================================================================\n",
      "437\n",
      "==============================\n",
      "Provide support in evaluating the operational effectiveness and suitability of the Multifunctional Information Distribution System Joint Tactical Radio System (MIDS JTRS) as installed in the F/A-18 during structured integrated and follow-on operational test and evaluation (FOT&E), and any integrated/operational testing support required for emerging capabilities, to include Tactical Targeting Network Technology (TTNT). Support the Commander, Operational Test and Evaluation Force (COMOPTEVFOR) in test planning, analysis and reporting by providing assistance and standardization to command test engineers, analysts, operational test directors (OTD) and operational test coordinators (OTC). Contribute to an upgrade of the command knowledge based management system by identifying requirements to support the operational processes of test planning and analysis.   Responsibilities include the following:  • Review program documentation and provide comments to include, but not limited to: Required Operating Procedures and Potential Operating Environment, Universal Navy/Joint Task List, Concept of Operations, Mission Needs Statements, Test and Evaluation Master Plan (TEMP), Capability Development Document, Capability Production Document, Navy Training Plan, manning documents, Program Acquisition Logistics Support Plan, test plans, test reports, training manuals, operator and maintenance manuals, and other documents as required by the OTC/OTD to better support the MIDS JTRS program • Assist in the development of Mission-Based Test Design and Integrated Evaluation Framework for Integrated Test and FOT&E in accordance with COMOPTEVFOR standards and checklists • Assist in the development of critical operational issues for operational testing • Assist in the development of scenarios for OT&E, and compile data necessary to draft the tests and test plans, both integrated and operational • Conduct background research and provide analytical and statistical analysis support and recommendations for the development of data collection plans for testing operational effectiveness and suitability • Draft TEMP comments and the TEMP Part III and applicable portions of Part IV, and other TEMP sections as necessary • Devise test matrices and procedures to satisfy COMOPTEVFOR/VX-9 testing objectives • Determine data reduction/reconstruction requirements , including hardware and software resources necessary for data collection and storage; identify facilities that can provide this processing, and prepare appropriate documentation to support the required services • Provide support in conducting liaison with modeling proponents, integrated verification and validation agents, developing agencies, Navy laboratories, service cryptologic agencies, Navy operational commands, other U.S. Government agencies, and hardware/software contractors to ensure that modeling and simulation (M&S) OT&E requirements are adequately addressed to permit timely and effective accreditation of M&S in support of MIDS JTRS OT&E • Develop methods and practices for how M&S can be used to supplement OT&E and help manage testing risk • Provide support in maintaining an M&S database that consists of the version and accreditation status of all M&S used in OT&E. • Attend program review meetings with OTD/OTC during the timeframe in various locations and provide technical reports • Assist OTD/OTC as required in briefing test participants, emphasizing the objectives of the test event and specific data-gathering requirements for each participant • Observe demonstrations and test events as appropriate with OTD/OTC • Collect test data and provide technical reports • Provide technical comment on changes made to the draft test plan, both integrated and operational during staffing at COMOPTEVFOR/ VX-9 • Perform data reduction and statistical analysis of data to ensure data validity, prior to more detailed data processing in accordance with 6PP process and procedures • Correlate data using appropriate statistical techniques to analyze operational effectiveness and suitability tests • Provide follow-up assistance as necessary on test reports and briefs • Provide support in writing “Blue” and “Gold” risk/deficiency sheets as required by the OTC. These documents shall be written in accordance with COMOPTEVFOR 6PP procedures and command templates • Provide the OTC/OTD with trip reports and monthly reports including the progress of work on assigned tasks, conferences/meetings attended, work plans and the expenditure of funds, and labor hours during the month • Provide support in conducting liaison with developing agencies, Navy laboratories, Navy Operational Commands, other U.S. Government agencies, and hardware/software contractors to ensure that OT&E requirements are adequately addressed to permit timely and effective testing REQUIRED EXPERIENCE • Navy, Marine Corps, Army, or Air Force fixed wing aviator. • Current working knowledge of the F/A-18 mission areas and current familiarity with F/A-18 systems • Possess a combination of ten (10) years operational experience and/or T&E experience • Possess a current working knowledge of DoD/DoN instructions and policies with respect to T&E including Requirements Documents, Capabilities Documents, and TEMPs • Demonstrated skill in formulating, directing, interpreting, and applying test planning/philosophy/policy to ensure T&E products are scientifically valid, analytically adequate, and creditable in testing • Demonstrated experience assisting with the technical writing aspects of all test documentation complying with COMOPTEVFOR standards, and a familiarity with current COMOPTEVFOR policy and procedures • Demonstrated ability to independently verify program testing generated data, to include performing complex calculations and explaining results in everyday language • Demonstrated writing and editing skills • Demonstrated proficiency with MS Office (emphasis on MS Excel and MS Word) and other software packages   DESIRED EXPERIENCE • Navy or Marine Corps fixed wing aviator. • Completion of the IEF course (highly desirable) • Operational experience and/or T&E experience with F/A-18 systems and data links, specifically Link 16, TACAN, and MIDS • Working knowledge of tactical operations, and the mission and role of DoD commands and units tasked to operate in a multi-threat environment • Demonstrated experience with DT, OT&E, or FOT&E, to include Test Plan development and execution and TEMP development in the last two (2) years • Demonstrated experience with the technical writing aspects of all test documentation and reports complying with COMOPTEVFOR standards, and an understanding of COMOPTEVFOR policy and procedures (e.g. test plan, 6PP, and final report formats) in the last two (2) years • DAWIA T&E Level II certified • Degree in an Engineering/Science field • Demonstrated experience with operational test design, to include:  o Knowledge of arithmetic, algebra, geometry, calculus, statistics, and their applications o Using logic and reasoning to identify the strengths and weaknesses of alternative solutions, conclusions, or approaches to problems o Identifying complex problems and reviewing related information to develop and evaluate options and implement solutions o Using scientific rules and methods to solve problems o Identifying measures or indicators of system performance and the actions needed to improve or correct performance, relative to the goals of the system o Choosing the right mathematical methods or formulas to solve a problem o Familiarity with operational test design software, such as “Statistica”, or “Design-Expert”  SECURITY CLEARANCE • SECRET required • Must be able to obtain TOP SECRET  Travel up to 25% to Pax River area and other test sites. \n",
      "================================================================================\n",
      "================================================================================\n",
      "1111\n",
      "==============================\n",
      "Data Warehouse Analyst II  Provide support for data warehousing initiatives and monitor data warehousing system to ensure reliability and accuracy of information loaded into the databases. Lead the design and development of data warehouse and business intelligence reports to support business objectives. Perform analysis and testing of relational databases and investigate any data load failures or data retrieval issues. Possesses experience in design and development with a focus on data warehousing, business intelligence, reporting solutions, and data integration of internal business systems across multiple functional areas. Proven methodology experience for complex systems integration projects and demonstrated ability to achieve deliverables on time and on budget. Career-Development position within field. Requires moderate skill sets and developing proficiency within discipline. Conducts tasks and assignments as directed. Works with moderate supervision with some latitude for independent judgment performing a variety of complex tasks, a wide degree of creativity and latitude is expected. Typically requires five to six years experience or equivalent education.   The individual will be working on Data Warehouse & BI projects, gathering & documenting requirements, designing solutions, developing ETL using Informatica PowerCenter, developing universes and reports using Business Objects, testing, and implementing solution.   Ideal candidate will have experience designing Data warehouse and BI solutions, and development experience with both Informatica PowerCenter and Business Objects.   *BI Knowledge areas:* 1. Data warehouse/data marts using Kimball & Inmon methodologies  2. Informatica PowerCenter ETL  3. SAP Business Objects reporting design/development  4. Xcelcius Dashboards and dashboard design  5. Crystal reporting  6. Oracle, DB2 and SQL Server  7. Dimensional Data Modeling  8. Slowly Changing Dimensions  9. Infoburst.  10. Requirements gathering  11. Project Management  12. Excellent written and oral communications  13. Independent worker   *Informatica PowerCenter - ETL (5+years experience):*  * Data warehouse design  * Data warehouse development   *Business Objects (5+ years experience):* * SAP Business Objects report design and development  * SAP Business Objects Universe design and development  * Xcelsius dashboards   *Database Knowledge (5+years experience):*  * ORACLE  * SQL Server  * DB2  * Complex SQL statements   *General Competencies* Bachelor's Degree in Computer Science or Software Engineering Able to work independently | 5+ Yrs. Analytical/problem solving skills | 5+ Yrs. Excellent Communication Skills | 5+ Yrs. Excellent oral and written communication skills | 5+ Yrs. *Information Technology - Commonly Used Software* MS Office products | 5+ Yrs. Outlook (MS) | 5+ Yrs. *Information Technology - Databases* Data analysis | 5+ Yrs. Data Warehouse - Experience in data warehouse design and development | 5+ Yrs. Data Warehouse - Experience in requirements gathering for data warehouse | 5+ Yrs. DB2 | 5+ Yrs. Informatica | 5+ Yrs. Knowledge of Oracle PL/SQL | 5+ Yrs. MS SQL Server | 5+ Yrs. Oracle | 5+ Yrs. *Information Technology - Design* Develop design specifications | 5+ Yrs. Knowledge of Kimball data warehouse design principals | 5+ Yrs. *Information Technology - Languages/Tools* Business Objects | 5+ Yrs. SAS | 2+ Yrs. *Information Technology - Requirements* Requirements analysis | 5+ Yrs. Requirements gathering | 5+ Yrs. *Information Technology - Testing* Conduct unit and system tests | 5+ Yrs. Develop Test Plans, Test Cases, and Test Procedures | 5+ Yrs. Identify defects | 5+ Yrs. Interpret test results | 5+ Yrs.\n",
      "================================================================================\n",
      "================================================================================\n",
      "4045\n",
      "==============================\n",
      "Do you love data the way biscuits love butter? Are you unnaturally excited by the prospect of balancing your love of numbers with your ability to understand user actions? Oh, and can you maintain reports, dashboards, and metrics with one hand while making a giant sandwich with the other? Ok, the sandwich isn’t actually required but we’d be super impressed if you did.    Hey there, we’re Eat24. We make it rain cheeseburgers across America, and we’re looking for a kick-ass, jack of all trades guru to join the team and help take things to the next level with our data. We’re talking product data, marketing data, business data...all kinds of data. Seriously, the phrase “same s***, different day” will never come out of your mouth so long as you’re here because you’ll have your hands in so many cookie jars.  Responsibilities Include:  -Apply your expertise in quantitative analysis, data mining, and the presentation of data to see beyond the numbers and understand how our users interact with our core products -Partner with Product and Engineering teams to solve problems and identify trends and opportunities -Inform, influence, support, and execute our product decisions -Build/maintain reports, dashboards, and metrics to monitor the performance of our products -Mine massive amounts of data and extract useful product insights -Manage development of data resources, gather requirements, organize sources, and support product launches  Background Requirements -3+ years experience doing quantitative analysis preferably for a social web company -Experience with large data sets and distributed computing (Hive/Hadoop) a plus -Ability to initiate and drive projects to completion with minimal guidance -The ability to communicate the results of analyses in a clear and effective manner -Basic understanding of statistical analysis, experience with packages such as R, MATLAB, SPSS, SAS, Stata, etc. preferred    Sound good? Well what are you waiting for? Shoot us your resume with a brief cover letter about why we’d be crazy not to hire you. We'll be waiting.\n",
      "================================================================================\n",
      "================================================================================\n",
      "3252\n",
      "==============================\n",
      "***Candidates must be responsible for any relocation fees.     POSITION SUMMARY Apply engineering theory and principles to problems of industrial layout or manufacturing production. May study and record time, motion, method, and speed involved in performance of production, maintenance, clerical, and other worker operations for such purposes as establishing standard production rates or improving efficiency. Maintain BPCS cost information, routing accuracy & updates.Provide analysis of \\\"what if\\\" senarios. Validate cost savings projects.   ________________________________________  ESSENTIAL FUNCTIONS  Essential Functions Statement(s) •  Interpret engineering drawings, schematic diagrams, or formulas and confer with management or engineering staff to determine quality and reliability standards.   •  Recommend revision to methods of operation, material handling, equipment layout, or other changes to increase production or improve standards.    •  Study time, motion, methods, and speed involved in maintenance, production, and other operations to establish standard production rate and improve efficiency.    •  Read worker logs, product processing sheets, or specification sheets to verify that records adhere to quality assurance specifications.   •  Observe worker using equipment to verify that equipment is being operated and maintained according to quality assurance standards.   •  Interpret engineering drawings, schematic diagrams, or formulas and confer with management or engineering staff to determine quality and reliability standards. Provide daily supervision to IT department and QC lab.    •  Recommend modifications to existing quality or production standards to achieve optimum quality within limits of equipment capability.    •  Compile and evaluate statistical data to determine and maintain quality and reliability of products.   •  Prepare charts, graphs, or diagrams to illustrate workflow, routing, floor layouts, material handling, or machine utilization.   •  Aid in planning work assignments in accordance with worker performance, machine capacity, production schedules, and anticipated delays.    •  Observe worker using equipment to verify that equipment is being operated and maintained according to quality assurance standards.    •  Study time, motion, methods, or speed involved in maintenance, production, or other operations to establish standard production rate or improve efficiency.   •  Design new equipment and materials or recommend revision to methods of operation, material handling, equipment layout, or other changes to increase production or improve standards.   •  Observe workers operating equipment or performing tasks to determine time involved and fatigue rate using timing devices.    •  Prepare charts, graphs, and diagrams to illustrate workflow, routing, floor layouts, material handling, and machine utilization.    •  Aid in planning work assignments in accordance with worker performance, machine capacity, production schedules, or anticipated delays.   •  Recommend modifications to existing quality or production standards to achieve optimum quality within limits of equipment capability.   •  Evaluate data and write reports to validate or indicate deviations from existing standards.    •  Read worker logs, product processing sheets, and specification sheets, to verify that records adhere to quality assurance specifications.    •  Evaluate data and write reports to validate or indicate deviations from existing standards.   •  Prepare graphs or charts of data or enter data into computer for analysis.   •  Prepare graphs or charts of data or enter data into computer for analysis.    •  Select products for tests at specified stages in production process, and test products for performance characteristics and adherence to specifications.    •  Record test data, applying statistical quality control procedures.   •  Select products for tests at specified stages in production process, and test products for performance characteristics and adherence to specifications.   •  Compile and evaluate statistical data to determine and maintain quality and reliability of products.    •  Enter new costs & verify correct routings.    •  Observe workers operating equipment or performing tasks to determine time involved and fatigue rate using timing devices.   •  Evaluate industrial operations for compliance with permits or regulations related to the generation, storage, treatment, transportation, or disposal of hazardous materials or waste.   •  Other duties as assigned.    •  Initiate or participate in emergency response procedures to contain, secure, or clean spills of hazardous materials.   •  Monitor environmental management systems for compliance with environmental policies, programs, or regulations.   •  Operate industrial hygiene equipment in manufacturing environments to reduce exposure to environmental contaminants.     POSITION QUALIFICATIONS Competency Statement(s)  •  Accountability - Ability to accept responsibility and account for his/her actions.   •  Accuracy - Ability to perform work accurately and thoroughly.   •  Analytical Skills - Ability to use thinking and reasoning to solve a problem.   •  Deductive Reasoning - Ability to apply principles of logical or scientific thinking to a wide range of intellectual and practical problems.   •  Detail Oriented - Ability to pay attention to the minute details of a project or task.   •  Honesty / Integrity - Ability to be truthful and be seen as credible in the workplace.   •  Innovative - Ability to look beyond the standard solutions.   •  Organized - Possessing the trait of being organized or following a systematic method of performing a task.   •  Problem Solving - Ability to find a solution for or to deal proactively with work-related problems.   •  Research Skills - Ability to design and conduct a systematic, objective, and critical investigation.   •  Safety Awareness - Ability to identify and correct conditions that affect employee safety.     SKILLS & ABILITIES  Education: Bachelor's Degree (four year college or technical school): Required    Experience: No prior experience necessary   Computer Skills: Microsoft Office with emphasis on Excel.      Certifications & Licenses:       Other Requirements:       PHYSICAL DEMANDS  N (Not Applicable)  Activity is not applicable to this position.  O (Occasionally)  Position requires this activity up to 33% of the time (0 - 2.5+ hrs/day)  F (Frequently)  Position requires this activity from 33% - 66% of the time (2.5 - 5.5+ hrs/day)  C (Constantly)  Position requires this activity more than 66% of the time (5.5+ hrs/day)         Physical Demands  Lift/Carry  Stand  F  Walk  F  Sit  F  Manually Manipulate  O  Reach Outward  O  Reach Above Shoulder  O  Climb  N  Crawl  N  Squat or Kneel  N  Bend  N   10 lbs or less  O  11-20 lbs  O  21-50 lbs  N  51-100 lbs  N  Over 100 lbs  N   Push/Pull  12 lbs or less  O  13-25 lbs  O  26-40 lbs  N  41-100 lbs  N     Other Physical Requirements  •  Vision (Near, Distance, Peripheral, Depth)  •  Ability to wear Personal Protective Equipment (PPE) - Eye, ear and non-slip footwear.    WORK ENVIRONMENT  Office primarily, plant frequently.\n",
      "================================================================================\n",
      "================================================================================\n",
      "2269\n",
      "==============================\n",
      "Busy GYN Practice looking for an experienced Billing Manager.  ILLUSTRATIVE EXAMPLES OF WORK: A. Billing and Coding: - Evaluates medical record documentation in order to optimize reimbursement by ensuring that the diagnostic and procedural codes and other documentation accurately reflect and support the outpatient visit, and to ensure that data comply with legal standards and guidelines - Interprets medical information such as diseases or symptoms, and diagnostic descriptions and procedures for a given visit in order to accurately assign and sequence the correct ICD-9-CM and CPT codes - Reviews claims before submission for completeness and accuracy and to oversee minimize claim denial; - Evaluates records and prepares reports, on such topics as number of denied claims or documentation or coding issues, for review by management - Makes recommendations for changes in policies and procedures - Provides technical guidance to physicians and other departmental staff in identifying and resolving issues or errors, such as incomplete or missing records and documentation, ambiguous or nonspecific documentation, or codes that do not conform to approved coding principles/guidelines; educates and advises staff on proper code selection, documentation, procedures, and requirements - Identifies training needs, prepares training materials, and conducts training for physicians and support staff to improve skills in the collection and coding of quality health data  - Reviews bulletins, newsletters, and periodicals, and attends workshops to stay abreast of current issues, trends, and changes in the laws and regulations governing medical record coding and documentation - Develops and updates procedures manuals to maintain standards for correct coding, minimize the risk of fraud and abuse, and optimize revenue recovery - Assist with the processing and reconciliation of the NYC Human Resources report (MOU) and work with the billing/data clerks to back bill to generate new revenue for the SBHCs  B. Data management and compliance - Provide back-up to the Revenue Manager regarding electronic billing and Managed Care claims and posting to AR - Review rejected encounter forms/electronic files and have necessary correction made by staff - Monitor timely submission of encounter forms/electronic files from the clinics and alert supervisor and clinic managers of any delays in submission or open visits in electronic health records systems (eCW) - Responsible for the timely and efficient flow of visit related forms/electronic systems from health care providers at all clinics to the billing/data management office - Works with Clinic Managers to develop and optimal data flow systems designed to meet the specific needs of each clinic. Ensures that the correct forms are available, completed and returned to the billing/data office in a timely manner. - Works with the Health Information Technology Manager and Software Support Specialist to update any forms/electronic systems related to billing/data collection. - Assist other staff in eliminating any billing backlog as necessary and as instructed by the immediate supervisor - Assists and support billing/data processing staff.  MINIMUM QUALIFICATIONS AND EXPERIENCE: - Bachelors Degree in related field - Graduate from a Credited Medical Coding and Billing School - Certified in Coding ; Preferred - At least 5 years of Medical Billing/Coding experience, GYN preferably - Knowledge of: ICD-9 (or updated version), and CPT coding guidelines; medical terminology - Knowledge of Medicaid and Medicaid Manage Care reimbursement guidelines - Knowledge and understanding of medical insurances policies and procedures - Knowledge of basic accounting procedures - Ability to research and analyze data and resolve issues; read, interpret and apply policies, procedures, laws, and regulations, read and interpret medical procedures and terminology - Prepare reports and related documents - Maintain working relationships with physicians and other staff - Knowledge of Microsoft Word and Excel a must - Strong customer service skills  Please send cover letter and resume\n",
      "================================================================================\n",
      "================================================================================\n",
      "1901\n",
      "==============================\n",
      "HBM nCode Federal LLC delivers software and expertise in test & measurement, product design, and operational monitoring, including CAE durability prediction and fatigue analysis.  Established in 1982, nCode is the leading supplier of durability, test and analysis products to a range of markets including aerospace, automotive, off highway, defense, and wind energy.  The Software Engineer will be responsible for developing and configuring software applications, interfaces and dashboards, to support HBM nCode customer requirements related to sensors, data measurements, data processing and data analysis. The position is based out of our Starkville, MS office.   RESPONSIBILITIES:   • Development of software applications for low cost data collection systems (Android, etc.) • Development of dashboards for nCode Automation on multiple user platforms (desktop, tablet, cell) • Development of software for low cost sensor implementations (current, etc.) • Development and configuration of data processing applications to autonomously transfer field data to back office applications • Generation of queries and report templates within nCode Automation to facilitate software applications and interfaces • Interpretation of data analysis results  • Prepare written and oral reports on the software application and results • Work with federal team to respond to RFQ’s and prepare data for sales presentations and reviews • Perform other duties as required  QUALIFICATIONS: • US Citizen (Requirement) • Ability to qualify for DoD security clearance (Requirement) • Computer Science/Computer Engineering degree or equivalent experience in software development (Requirement) • 1-3 years’ experience in software application development (Requirement) • Experience with scripting languages such as Python • Experience with C#, C++ or Java • Experience with sensor and measurement equipment development (such as the Arduino platform), data acquisition, vehicle usage monitoring • Familiarity with nCode software products and/or equivalent engineering analysis software • Good communication skills, both verbal and written • Willingness to travel domestically  BENEFITS:   HBM offers competitive benefits including medical, dental, life and disability insurance and 401(k) matching funds.  TO APPLY: Go to www.example.com.\n",
      "================================================================================\n",
      "================================================================================\n",
      "4063\n",
      "==============================\n",
      "The Publisher Operations team is responsible for managing technical and strategic operations for partnerships with eXelate’s vast portfolio of data providers. The team manages the onboarding of new data partners and all aspects of technical implementations and day-to-day operations to ensure accurate and consistent flow of valuable datasets.   Roles and Responsibilities  Organize and lead onboarding process for new data providers, and consult on taxonomy and tag implementation Create segments, implement/QA mapping, monitor volume, and communicate to internal teams and external clients Provide technical support to both online and offline data partners; address several clients over a short period of time to provide resolution, often working closely with backend technical team Analyze segment and data provider level reports, monitor to identify any issues impacting segment accuracy and volume, and proactively troubleshoot Primary contact for existing data partners; provide day-to-day support including ad-hoc requests and initiatives Collaborate with internal teams (sales/AM/data distribution/analytics) to ensure timely execution of deliverables Maintain eXelate Wiki for both internal and client-facing documents   Requirements  Bachelor’s Degree Attention to details, process and operations oriented, analytical Responsible, hard-working with positive attitude, able to manage multiple tasks and partnerships Solid communication skills Strong proficiency with Excel (preferably vlookups, pivot tables, and basic formulas)   Preferred Experience  1-3 years of prior experience in the online advertising space Ad operations, tech operations, client management, campaign management, and data targeting background highly preferred Experience with 3rd party media/data platforms a plus\n",
      "================================================================================\n",
      "================================================================================\n",
      "487\n",
      "==============================\n",
      "Who We Need:  Right now, we’re looking for a Finance Database Developer.  You will be working with our Finance department to create new reports, analyze sales data, and interface with our partners to exchange data.    Responsibilities:    - Write, debug, and optimize complex queries and stored procedures in SQL   - Verify the accuracy of reports  - Ensure security and integrity of transactional data  - Create, maintain, and optimize appropriately normalized and denormalized data structures  - Rearchitect system as appropriate for speed and maintainability  - Design and write ETL processes for data from many disparate sources  - Work in a collaborative team environment    Qualifications:    - 4 years of experience building and maintaining business-critical production databases  - Ability to deal with large, complex data sets  - Expert programming skills in SQL  - Experience with financial data systems preferred  - Excellent verbal and written communication skills  - Experience developing applications using Microsoft Access a plus  - Experience with Great Plains a plus  - Experience with other programming languages a plus (VB/VBA, Python, Java, C++, etc.)  - Passionate about data and a desire for continuous education  - BS in Computer Science or equivalent experience    We believe that great people deserve great benefits.  So we offer a highly competitive salary and a wealth of amazing benefits  - including company equity, 100% paid family medical, dental, vision, and a healthy 401k.  We’ll also throw in gym memberships, 12 holidays, career training, 3 weeks PTO and much more.     A Word About Our Culture. TRUECar is guided by world-class leadership who believes in providing you with the best.  We like to have fun while we’re changing the auto industry, and we utilize the latest web technologies to solve challenging problems, create innovative web applications from the ground up, and provide an outrageously good Web experience for our customers.  Invention and open collaboration are highly valued, and we encourage ‘Green Field’ thinking to continually push great ideas across the entire organization. If this sounds like the kind of place where you want to spend your valued time, then check us out at truecar.com. We want to hear from you.       Make the Connection.  Send us your resume, cover letter, and links to some of your latest projects, and we’ll be in touch.    \n",
      "================================================================================\n",
      "================================================================================\n",
      "2954\n",
      "==============================\n",
      "XIFIN, Inc ® offers a cloud-based application that provides accounts receivable and financial management solution for medical laboratories. Our Software as a Service (SaaS) model allows us to use best-of-breed technologies to benefit our customers.  Come join us in data integration development as senior developer. You will work closely with other engineers, database and system administrators, product management, and support services to specify, design, develop and test software to satisfy XIFIN data management and data integration needs.  Your Role Will Include:  - Eliciting technical requirements and change requests from product managers and other members of the team. - Designing, developing, reviewing and testing ETL code and other team members’ data integration and management scripts. - Working with and mentoring other members of the Engineering Department to improve quality, testability, and maintainability of code, and identifying opportunities for process improvement and implementing them. - Ensuring that quality is a priority and built into all stages of the development lifecycle.  Desired Skills and Experience:  - 3+ years of high level experience as a software integration engineer, proficient in SQL and ETL scripting and automated workflow. - Experience dealing with large data volume with scalable solutions. - Deep understanding of Oracle features such as partitioning, indexing, and other data warehouse features. - Excellent knowledge in commercial ETL tool, SAP Business Objects Data Integrator and Services. - Ability to work in all phases of the software development life-cycle. - Strong team orientation. - BS in Computer Science or equivalent experience.  Pluses Include:  - Perl, real-time data integration and data warehousing experience. - Financial industry/accounting and/or laboratory or other medical industry background. - Experience in fast-growing software development environments.  XIFIN is a Software-as-a-Service (SaaS) provider of Revenue Cycle Management (RCM) solutions that enable diagnostic service providers to improve financial performance through a compelling return on investment and rapid time-to-value.   XIFIN is an Equal Opportunity Employer and maintains a drug free workplace, including pre-employment drug testing.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "search(\"data scientist\", jobs_df['description'], doc_index, inv_index, avg_tfidf_df['idf'], tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These calculation of average $TF.IDF$, and the ability to search our documents is useful, but it would be nice to be able to visualize our analysis.\n",
    "\n",
    "### NEXT => [3. Visualizing](3. Visualizing.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
